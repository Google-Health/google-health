# Utilities for evaluating model and reader performance

This package contains functions for the statistical analysis of multi-reader multi-case (MRMC) studies, a common paradigm in the medical imaging literature.
For statistical considerations and sample usage, please see our open-access [technical report](https://www.medrxiv.org/content/10.1101/2022.05.06.22274773v1).

As of May 3, 2022, the following published work has used tools in this library:

* [Majkowska et al. (2019)](https://pubs.rsna.org/doi/full/10.1148/radiol.2019191293)
* [McKinney et al. (2020)](https://www.nature.com/articles/s41586-019-1799-6)
* [Sayres et al. (2020)](https://iovs.arvojournals.org/article.aspx?articleid=2769549)
* [Steiner et al. (2020)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7662146/)
* [Kazemzadeh et al. (2021)](https://arxiv.org/abs/2105.07540)
* [Liu et al. (2022)](https://www.sciencedirect.com/science/article/pii/S246865302200001X)

If you use this software in your own research, please cite our paper:

```
@article {McKinney2022,
  author = {McKinney, Scott Mayer},
  title = {Comparing human and AI performance in medical machine learning: An open-source Python library for the statistical analysis of reader study data},
  elocation-id = {2022.05.06.22274773},
  year = {2022},
  doi = {10.1101/2022.05.06.22274773},
  publisher = {Cold Spring Harbor Laboratory Press},
  URL = {https://www.medrxiv.org/content/10.1101/2022.05.06.22274773},
  eprint = {https://www.medrxiv.org/content/10.1101/2022.05.06.22274773.full.pdf},
  journal = {medRxiv}
}
```
